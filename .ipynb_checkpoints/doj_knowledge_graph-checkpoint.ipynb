{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb813b25",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d9fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8c1e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48050, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import DOJ sentences\n",
    "candidate_sentences = pd.read_csv(\"doj_api_data_new.csv\")\n",
    "candidate_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b7ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8280     BUFFALO, N.Y.--U.S. Attorney William J. Hochul, Jr. announced today that Myron Johnson, 39, of Buffalo, N.Y., who was convicted of possession with intent to distribute cocaine, was sentenced to 51...\n",
       "24831    Follow @SDILNews \\n\\nNAEEM MAHMOOD KOHLI, 60, of Effingham, Illinois, was convicted of seven counts of illegal dispensation of a Schedule II Controlled Substance following a 17-day jury trial held...\n",
       "4303     WASHINGTON – The Department of Justice and the Department of the Interior announced today that Freeport-McMoRan Corporation and Freeport-McMoRan Morenci Inc. (Freeport-McMoRan) have agreed to pay ...\n",
       "4782     A federal judge in Worcester, Mass., sentenced William Scott Dion today to 84 months in prison for conspiring to defraud the United States, and for obstructing the Internal Revenue Service (IRS), ...\n",
       "33373    St. Louis, MO – JOEY D. WOOD pled  guilty to filing four false tax returns for himself and two others claiming  refunds totaling over $23,000 for tax years 2011 and 2012. According to court docume...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_sentences['body'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91439772",
   "metadata": {},
   "source": [
    "### Entities Extraction\n",
    "To build a knowledge graph, the most important things are the nodes and the edges between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210d330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "    if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aceb5ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['film', '200  patents']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(\"the film had 200 patents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1ab20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 48050/48050 [2:02:33<00:00,  6.53it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_pairs = []\n",
    "\n",
    "for i in tqdm(candidate_sentences[\"body\"]):\n",
    "  entity_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b025d",
   "metadata": {},
   "source": [
    "Time it took to do it. Whenever doing with GPT model will need to develop prompts but doing through the API have to write code. If want relationships in a specif format, would have to create relationships into a file. But then how does Spacy do that? Is that the same order of time to do that in a GPT model? Can it do it automatically and faster? Is there a much lower bar to make it happen? Even if Spacy is better. \n",
    "\n",
    "When we start evaluating downfalls of these models that they don't have memory. The Raven one has infinite memory but looking at GPT based ones we have to use zero shot memory by injecting into data prompts themselves. Are there things that we can do to improve results? Is there an idea around extracting relationship information that even if GPT model does it so now we can inject it inot zero shot lerning to improve how it eva,uates on subsequent topics. Zero shot training. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
